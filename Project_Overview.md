# GenAI Project — Intelligent Form Extraction & Medical Chatbot

An end-to-end solution that automates structured data extraction from government forms (including handwriting and checkboxes) and provides a Retrieval-Augmented Generation (RAG) medical chatbot for Health Funds. Built as two coordinated phases: a document-extraction pipeline and a stateless chatbot microservice.

## Project Overview

This repository contains a proof-of-concept production-oriented system that demonstrates:
- Phase 1: Automated extraction of structured data from National Insurance forms using OCR and LLM-based post-processing.
- Phase 2: A stateless RAG-based medical chatbot microservice that answers Health Fund related questions using embeddings and a vector store.

Target users:
- Developers and reviewers evaluating a combined Document Intelligence + LLM architecture.
- Organizations needing an opinionated reference for extracting semi-structured handwritten forms and exposing an LLM-backed, queryable knowledge service.

Main technologies:
- Python 3.10+
- Azure Document Intelligence (for OCR / layout / handwriting)
- Azure OpenAI (LLM and embeddings)
- FastAPI + Uvicorn (backend microservice)
- Streamlit (UIs for Phase 1 & Phase 2)
- Pydantic (validation)
- Vector store (embeddings-backed retrieval)

## Key Features

- Accurate extraction of structured fields from scanned or photographed forms (handwriting and checkboxes).
- LLM-guided field extraction and validation to improve accuracy and handle ambiguous inputs.
- RAG-based chatbot that answers Health Fund questions using uploaded/ingested knowledge.
- Clear separation between document processing and conversational service for scalability.
- Developer-friendly Streamlit UIs for manual review and testing.

## Architecture / Design

High-level architecture:
- Phase 1 (Form Extraction)
  - Input: scanned form image
  - OCR & layout parsing: Azure Document Intelligence
  - LLM extraction: prompt-guided extraction to map OCR outputs into structured data
  - Validation: Pydantic schemas to enforce types and business rules
- Phase 2 (Chatbot Microservice)
  - Vector store of documents (embeddings generated by Azure OpenAI)
  - FastAPI backend serving retrieval + LLM responses
  - Stateless design: inference requests do not rely on local session state (RAG retrieves context per request)
  - Streamlit UI that calls the FastAPI backend for chatbot interactions

Design principles:
- Separation of concerns: document pipeline and chatbot are decoupled.
- Stateless backend for easier scaling and horizontal replication.
- Secrets and credentials kept out of source control (via environment variables).
- Input validation and schema-driven extraction for predictable outputs.

## Prerequisites

- OS: Windows, macOS, or Linux
- Python 3.10 or newer
- Git (optional)
- Azure subscription with:
  - Azure OpenAI resource (endpoint and key)
  - Azure Document Intelligence (Form Recognizer / Document Intelligence) resource (endpoint and key)
- Recommended: virtual environment tooling (venv)

## Installation & Setup

Assuming a clean machine and a cloned repository.

1. Create and activate a virtual environment

Windows:
```bash
python -m venv .venv
.venv\Scripts\activate
```

macOS / Linux:
```bash
python3 -m venv .venv
source .venv/bin/activate
```

2. Install project dependencies
```bash
pip install -r requirements.txt
```

3. Create the runtime configuration file (see Configuration below)

Optional: On Windows, use the included `Launcher.bat` to automate dependency installation and launch.

## Configuration

Create a `.env` file at the repository root with required environment variables. Do NOT commit this file.

Example `.env` (placeholders only):
```env
# Azure OpenAI
AZURE_OPENAI_ENDPOINT="https://your-openai-resource.openai.azure.com/"
AZURE_OPENAI_KEY="your_openai_key"

# Azure Document Intelligence / Form Recognizer
AZURE_DI_ENDPOINT="https://your-di-resource.cognitiveservices.azure.com/"
AZURE_DI_KEY="your_di_key"

# Optional: vector store / storage / app settings
VECTOR_STORE_PATH="./data/vectors"      # local path for embeddings (if used)
LOG_LEVEL="INFO"
```

Security notes:
- Keep keys secret and rotate regularly.
- For production, use a secrets manager (Azure Key Vault) or environment-specific secret provisioning.

## How to Run

There are two main modes: automatic launcher (Windows) and manual.

Option A — Automatic Launch (Windows)
- Double-click `Launcher.bat` (bundles install & launches services). Review the script before use.

Option B — Manual Launch (recommended for debugging)
Open three terminal windows (ensure the virtual environment is activated in each):

1) Backend Server (FastAPI)
```bash
uvicorn phase2.api:app --reload --host 0.0.0.0 --port 8000
```
- Default backend URL: http://localhost:8000

2) Phase 1 - Form Analysis UI (Streamlit)
```bash
streamlit run phase1_app.py --server.port 8501
```
- UI URL: http://localhost:8501

3) Phase 2 - Chatbot UI (Streamlit)
```bash
streamlit run phase2_app.py --server.port 8502
```
- UI URL: http://localhost:8502

Notes:
- Adjust ports to avoid conflicts.
- The Streamlit frontends communicate with the FastAPI backend for chatbot interactions (phase2).

## Project Structure

```bash
genai-assignment/                # project root
├── phase1/                      # Form Extraction pipeline
│   ├── ocr.py                   # Azure Document Intelligence wrapper and helpers
│   ├── llm_extractor.py         # LLM-based extraction prompts & orchestration
│   └── validator.py             # Pydantic schemas & validation rules
├── phase2/                      # Chatbot microservice
│   ├── api.py                   # FastAPI backend entry point (RAG endpoints)
│   ├── knowledge_loader.py      # Document ingestion, embeddings & vector store logic
│   ├── llm_client.py            # Azure OpenAI wrapper for chat & embeddings
│   ├── logger.py                # Central logging configuration
│   └── prompts.py               # System prompts and prompt templates
├── UI/                          # Static assets (background images, assets)
├── phase1_app.py                # Streamlit UI for Phase 1 (form analyzer)
├── phase2_app.py                # Streamlit UI for Phase 2 (chatbot)
├── Launcher.bat                 # Optional Windows launcher script
├── requirements.txt             # Python dependencies
└── Project_Overview.md          # Project overview and notes
```
## Future Improvements

- Dockerize services and provide docker-compose for local development and testing.
- Add automated tests (unit tests and integration tests) and CI pipeline.
- Integrate an authenticated deployment path (OAuth2 / API keys) for the API.
- Replace local vector store with a managed vector database and implement persistence/backup.
- Add batching, retry logic, and resilient error handling for external API failures.
- Provide sample datasets, end-to-end demo scripts, and performance benchmarks.
- Implement observability: metrics (Prometheus), traces (OpenTelemetry), and alerts.

## Contact / Contribution
- Author: yairlavy
